{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 필요한 패키지를 로드합니다.\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 56s 929us/step - loss: 0.0898 - acc: 0.1333\n"
     ]
    }
   ],
   "source": [
    "#아래의 Conv2D 함수의 인자인 input_shape 는 (samples, rows, cols, chennels) 의 4D Tensor 형태여야 하므로\n",
    "#Train data 를 모델에 넣기 위해서 (60000, 28, 28, 1) 의 4D Tensor 로 Reshape 해 줍니다.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#Train data 를 dloat 형태로 바꿔 줍니다.\n",
    "x_train = x_train.astype('float32')\n",
    "#255로 나눠 주어 pixel의 grayscale 값이 0에서 1 사이의 값을 가지게 해 줍니다.\n",
    "x_train /= 255\n",
    "#np.util에 있는 to_categorical은 주어진 레이블을 one-hot encoding 해 줍니다.\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "\n",
    "\n",
    "# 모델 구성(2(input) -> CONV(ReLU) -> CONV(ReLU) -> FC(sigmoid))\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Convolution2D(input_shape = (28, 28, 1), filters = 10, kernel_size = (3,3), strides = 1, padding = 'same'))\n",
    "#Activation Function 으로 Relu를 사용하였습니다.\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(filters = 15, kernel_size = (3,3), strides = 1))\n",
    "model.add(Activation('relu'))\n",
    "#이미지의 차원을 줄이기 위해서 Pooling Layer를 넣었습니다.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#0.25의 확률의 Dropout 시행\n",
    "model.add(Dropout(0.25))\n",
    "#FC Layer에 넣기 위해서 2차원 배열로 되어 있는 이미지 인풋을 Flattern 해 줍니다.\n",
    "model.add(Flatten())\n",
    "#Output Node 가 128개인 FC Layer\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "#Output Node 가 10개인 FC Layer\n",
    "model.add(Dense(10))\n",
    "#Output 벡터의 합을 1로 만들어주기 위해서 softmax 함수를 사용했습니다.\n",
    "model.add(Activation('softmax'))\n",
    "#Keras Documentation 을 참고하여 Adam Optimizer 를 이용하였습니다.\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics = ['accuracy'])\n",
    "#CNN 모델을 학습시킵니다. 학습 결과는 History object에 저장됩니다.\n",
    "history = model.fit(x_train,y_train , epochs=1, batch_size=100, verbose = 1)\n",
    "#best parameter를 저장합니다.\n",
    "#save_model(model, 'best_param.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 10)\n",
      "(28, 28, 10)\n",
      "(26, 26, 15)\n",
      "(26, 26, 15)\n",
      "(13, 13, 15)\n"
     ]
    }
   ],
   "source": [
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[0].output])\n",
    "#layer_output = get_3rd_layer_output([x])[0]\n",
    "layer_output = get_3rd_layer_output([x_train])[0]\n",
    "print(np.array(layer_output[1]).shape)\n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])\n",
    "#layer_output = get_3rd_layer_output([x])[0]\n",
    "layer_output = get_3rd_layer_output([x_train])[0]\n",
    "print(np.array(layer_output[1]).shape)\n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[2].output])\n",
    "#layer_output = get_3rd_layer_output([x])[0]\n",
    "layer_output = get_3rd_layer_output([x_train])[0]\n",
    "print(np.array(layer_output[1]).shape)\n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[3].output])\n",
    "#layer_output = get_3rd_layer_output([x])[0]\n",
    "layer_output = get_3rd_layer_output([x_train])[0]\n",
    "print(np.array(layer_output[1]).shape)\n",
    "\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[4].output])\n",
    "#layer_output = get_3rd_layer_output([x])[0]\n",
    "layer_output = get_3rd_layer_output([x_train])[0]\n",
    "print(np.array(layer_output[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60000, 26, 26, 15)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(layer_output).shape\n",
    "get_layer_output = backend.function([model.layers[0].input], [model.layers[3].output])\n",
    "layer_output = get_layer_output([x_test])[0]\n",
    "\n",
    "for feature_map in output_list:\n",
    "    output_shape = np.array(layer_output).shape\n",
    "    for filter_index in range(len(output_shape[3])):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(np.array(layer_output[5,:,:,1]), cmap = 'gray')\n",
    "        plt.savefig(  + filter_index + '].png')\n",
    "        # flush\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26, 15)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(layer_output[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Train Log 를 텍스트 파일로 저장합니다.\n",
    "    filename = 'train_log.txt'\n",
    "    f = open(filename, 'w')\n",
    "    f.write('=============Train Result==========\\n')\n",
    "    \n",
    "    log_list = history.history['acc']\n",
    "    for i in range(len(log_list)):\n",
    "        f.write('Epoch ' + str(i+1) + ' - Error Rate : ' + str(log_list[i]) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "get_layer_output = backend.function([model.layers[0].input], [model.layers[3].output])\n",
    "layer_output = get_layer_output([x_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(layer_output[0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#0과 1에 해당되는 Feature Map을 출력할 예정입니다.\n",
    "#Test Data Set의 55번째, 69번째, 71번째 데이터의 Label 의 0이고\n",
    "#57, 74, 89번째 Label이 1이므로 이에 해당하는 데이터만 리스트에 저장하겠습니다.\n",
    "\n",
    "sample_list = [55, 69, 71, 57, 74, 89]\n",
    "\n",
    "for i in sample_list:\n",
    "    output_shape = np.array(layer_output[0][i]).shape\n",
    "    for filter_index in range(len(output_shape[3])):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(np.array(layer_output[0][i,:,:,filter_index]), cmap = 'gray')\n",
    "        plt.savefig('[' + str(y_test[i]) +  '_' + str(i) + '_' + filter_index + '].png')\n",
    "        # flush\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1dfa6646d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.array(layer_output[0][55,:,:,1]), cmap = 'gray')\n",
    "# np.array(layer_output[0][55,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "type(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_log.txt'\n",
    "f = open(filename, 'w')\n",
    "f.write('=============Train Result==========\\n')\n",
    "    \n",
    "log_list = history.history['acc']\n",
    "for i in range(len(log_list)):\n",
    "    f.write('Epoch ' + str(i+1) + ' - Error Rate : ' + str(log_list[i]) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
